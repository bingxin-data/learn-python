{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from scipy.stats import pointbiserialr\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Understand the Problem and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('conversion_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    uniques = sorted(df[col].unique())\n",
    "    print(f\"{col:<20}{len(uniques):<5}{uniques[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i. Handle Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Domain-Specific Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The age variable has a maximum of 123, which might be unrealistic.\n",
    "# Cap or remove outliers using the 99th percentile.\n",
    "# df['age'] = np.where(df['age'] > 100, 100, df['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['age']>100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df['age']>100)] # There are only two records that is invalid, let's first remove them directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Statistical Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Z-Score Method\n",
    "Measures how far a data point is from the mean in terms of standard deviations.\n",
    "- A common threshold is |z| > 3.\n",
    "- Use Case: Normally distributed data.\n",
    "- Limitations: Sensitive to non-normal distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate Z-scores\n",
    "# data['z_score'] = (data['value'] - data['value'].mean()) / data['value'].std()\n",
    "\n",
    "# # Identify outliers\n",
    "# outliers = data[np.abs(data['z_score']) > 3]\n",
    "# print(outliers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Interquartile Range (IQR) Method\n",
    "Defines outliers as data points outside the range [Q1 - 1.5*IQR, Q3 + 1.5*IQR].\n",
    "- Use Case: Skewed or non-normal distributions.\n",
    "- Strength: Less sensitive to outliers than Z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate IQR\n",
    "# Q1 = data['value'].quantile(0.25)\n",
    "# Q3 = data['value'].quantile(0.75)\n",
    "# IQR = Q3 - Q1\n",
    "\n",
    "# # Define bounds\n",
    "# lower_bound = Q1 - 1.5 * IQR\n",
    "# upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# # Identify outliers\n",
    "# outliers = data[(data['value'] < lower_bound) | (data['value'] > upper_bound)]\n",
    "# print(outliers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Visualization Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Boxplot\n",
    "Highlights outliers beyond the whiskers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Scatter Plot\n",
    "Visualize relationships between two variables and detect outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Distribution Plot\n",
    "Check for unusual peaks or long tails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Machine Learning-Based Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Isolation Forest\n",
    "Anomaly detection algorithm that isolates outliers in the data.\n",
    "\n",
    "- Use Case: Multivariate or high-dimensional data.\n",
    "- Strength: Works well with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# # Train Isolation Forest\n",
    "# iso = IsolationForest(contamination=0.05, random_state=42)\n",
    "# data['anomaly'] = iso.fit_predict(data[['value']])\n",
    "\n",
    "# # Anomalies are labeled as -1\n",
    "# outliers = data[data['anomaly'] == -1]\n",
    "# print(outliers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. Missing or Incorrect Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i. Univariate Analysis\n",
    "Analyze each feature independently to understand its distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Numerical Features\n",
    "\n",
    "- Histogram\n",
    "- Boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for each group\n",
    "df.groupby('converted')['age'].describe().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Visualize the Distributions\n",
    "What to Look For:\n",
    "- Are there clusters or gaps in age (e.g., young users dominating the data)?\n",
    "- Are there outliers (e.g., extremely high ages)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE plot: Compare age distributions\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.kdeplot(data=df, x=\"age\", hue=\"converted\", fill=True, common_norm=False, ax=ax[0])\n",
    "ax[0].set_title(\"Age Distribution by Conversion Status\")\n",
    "ax[0].set_xlabel(\"Age\")\n",
    "ax[0].set_ylabel(\"Density\")\n",
    "\n",
    "# Boxplot: Compare age distributions\n",
    "sns.boxplot(data=df, x=\"converted\", y=\"age\", ax=ax[1])\n",
    "ax[1].set_title(\"Boxplot of Age by Conversion Status\")\n",
    "ax[1].set_xlabel(\"Conversion Status\")\n",
    "ax[1].set_ylabel(\"Age\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pages Visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE plot: Compare total_pages_visited distributions\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.kdeplot(data=df, x=\"total_pages_visited\", hue=\"converted\", fill=True, common_norm=False, ax=ax[0])\n",
    "ax[0].set_title(\"Pages Visited Distribution by Conversion Status\")\n",
    "ax[0].set_xlabel(\"Pages Visited\")\n",
    "ax[0].set_ylabel(\"Density\")\n",
    "\n",
    "# Boxplot: Compare total_pages_visited distributions\n",
    "sns.boxplot(data=df, x=\"converted\", y=\"total_pages_visited\", ax=ax[1])\n",
    "ax[1].set_title(\"Boxplot of Pages Visited by Conversion Status\")\n",
    "ax[1].set_xlabel(\"Conversion Status\")\n",
    "ax[1].set_ylabel(\"Pages Visited\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Categorical Features\n",
    "- Frequency counts\n",
    "- Bar plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "sns.countplot(data=df, x='country', hue='converted', ax=ax[0])\n",
    "ax[0].set_title(\"Count Plot of Country \")\n",
    "sns.barplot(data=df, x='country', y='converted', ax=ax[1])\n",
    "ax[1].set_title('Conversion Rate per Country')\n",
    "ax[1].set_ylabel(\"Conversion Rate\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "sns.countplot(data=df, x='new_user', hue='converted', ax=ax[0])\n",
    "ax[0].set_title(\"Count Plot of User Types\")\n",
    "sns.barplot(data=df, x='new_user', y='converted', ax=ax[1])\n",
    "ax[1].set_title('Conversion Rate per User Type')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "sns.countplot(data=df, x='source', hue='converted', ax=ax[0])\n",
    "ax[0].set_title(\"Count Plot of Sources\")\n",
    "sns.barplot(data=df, x='source', y='converted', ax=ax[1])\n",
    "ax[1].set_title('Conversion Rate per Source')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. Multivariate Analysis\n",
    "Explore relationships between two or more features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Correlation Analysis (Numerical Features)\n",
    "- Compute pairwise correlations.\n",
    "- Scatter Plots\n",
    "- Pair Plot: Visualize pairwise relationships among all numerical features.\n",
    "- Point-Biserial Correlation: Since converted is binary, the Point-Biserial Correlation is more suitable for quantifying the relationship.\n",
    "    - If p < 0.05, the correlation is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Between Age, Pages, and Conversion\n",
    "What to Look For:\n",
    "- If age and total_pages_visited are highly correlated, normalization may be redundant.\n",
    "- If both are weakly correlated with converted individually but together show stronger relationships, normalization or interaction terms may help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix for the numerical features\n",
    "correlation_matrix = df[['age', 'total_pages_visited', 'converted']].corr()\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', cbar=True)\n",
    "plt.title('Correlation Matrix for Numerical Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, diag_kind=\"kde\", corner=True, markers=\"o\")\n",
    "plt.suptitle(\"Pair Plot of Numerical Features\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation, p_value = pointbiserialr(df['converted'], df['age'])\n",
    "print(f\"Point-Biserial Correlation: {correlation:.2f}, p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Categorical vs. Numerical Features\n",
    "Compare distributions of numerical features across categories.\n",
    "\n",
    "- Boxplot\n",
    "- Violin Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots to compare categorical and numerical features side by side\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 16))\n",
    "\n",
    "# Age distribution by Country\n",
    "sns.boxplot(x='country', y='age', data=df, ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"Age Distribution by Country\")\n",
    "axes[0, 0].set_xlabel(\"Country\")\n",
    "axes[0, 0].set_ylabel(\"Age\")\n",
    "\n",
    "# Total pages visited by Country\n",
    "sns.boxplot(x='country', y='total_pages_visited', data=df, ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"Total Pages Visited by Country\")\n",
    "axes[0, 1].set_xlabel(\"Country\")\n",
    "axes[0, 1].set_ylabel(\"Total Pages Visited\")\n",
    "\n",
    "# Age distribution by Source\n",
    "sns.boxplot(x='source', y='age', data=df, ax=axes[1, 0])\n",
    "axes[1, 0].set_title(\"Age Distribution by Source\")\n",
    "axes[1, 0].set_xlabel(\"Source\")\n",
    "axes[1, 0].set_ylabel(\"Age\")\n",
    "\n",
    "# Total pages visited by Source\n",
    "sns.boxplot(x='source', y='total_pages_visited', data=df, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Total Pages Visited by Source\")\n",
    "axes[1, 1].set_xlabel(\"Source\")\n",
    "axes[1, 1].set_ylabel(\"Total Pages Visited\")\n",
    "\n",
    "# Age distribution by new_user status\n",
    "sns.boxplot(x='new_user', y='age', data=df, ax=axes[2, 0])\n",
    "axes[2, 0].set_title(\"Age Distribution by New User Status\")\n",
    "axes[2, 0].set_xlabel(\"New User\")\n",
    "axes[2, 0].set_ylabel(\"Age\")\n",
    "\n",
    "# Total pages visited by new_user status\n",
    "sns.boxplot(x='new_user', y='total_pages_visited', data=df, ax=axes[2, 1])\n",
    "axes[2, 1].set_title(\"Total Pages Visited by New User Status\")\n",
    "axes[2, 1].set_xlabel(\"New User\")\n",
    "axes[2, 1].set_ylabel(\"Total Pages Visited\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Age Distribution by Country\n",
    "    - The median age is similar across all countries (around 30).\n",
    "    - The US has a slightly narrower interquartile range, meaning the age distribution is more consistent compared to the other countries.\n",
    "    - Outliers (older users) are present in all countries but appear more frequently in the US.\n",
    "- Total Pages Visited by Country\n",
    "    - All countries have a similar median for pages visited, with most users visiting around 4–5 pages.\n",
    "    - Outliers exist in all countries where users have visited significantly more pages (over 20).\n",
    "    - The US shows slightly more variability in total pages visited compared to the other countries.\n",
    "- Age Distribution by Source\n",
    "    - Users from all sources have a similar median age of around 30.\n",
    "    - Users from Ads show slightly more variability in age, with a broader interquartile range.\n",
    "    - Outliers are present in all sources but are more prominent for users from Ads.\n",
    "- Total Pages Visited by Source\n",
    "    - Users from all sources have a similar median for pages visited, with most users visiting around 4–5 pages.\n",
    "    - Users from SEO show slightly more variability, with more outliers (users visiting over 20 pages).\n",
    "- Age Distribution by New User Status\n",
    "    - The median age for both new and returning users is around 30.\n",
    "    - The distribution is nearly identical for both groups, with no clear distinction.\n",
    "- Total Pages Visited by New User Status\n",
    "    - Both groups have a similar distribution for pages visited, with medians around 4–5 pages.\n",
    "    - Outliers (users visiting many more pages) exist in both groups, but there is no significant difference in variability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pages Visited vs. Conversion Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "data = df.groupby('total_pages_visited')['converted'].mean().reset_index()\n",
    "sns.lineplot(data=df, x='total_pages_visited', y='converted', marker='o', linestyle='-', color='#F7B32B', ax=ax[0,0])\n",
    "ax[0,0].set_title(\"Conversion Rate vs. Pages Visited\")\n",
    "ax[0,0].set_xlabel(\"Pages Visited\")\n",
    "ax[0,0].set_ylabel(\"Conversion Rate\")\n",
    "ax[0,0].grid(True)\n",
    "\n",
    "\n",
    "sns.lineplot(data=df, x='total_pages_visited', y='converted', hue='new_user', marker='o', ax=ax[1,0])\n",
    "ax[1,0].set_title('Conversion Rate vs. Pages Visited by New User Status')\n",
    "ax[1,0].set_xlabel('Pages Visited')\n",
    "ax[1,0].set_ylabel('Conversion Rate')\n",
    "ax[1,0].legend(title='New User (1 = New, 0 = Existing)')\n",
    "ax[1,0].grid(True)\n",
    "\n",
    "sns.lineplot(data=df, x='total_pages_visited', y='converted', hue='country', marker='o', ax=ax[0,1])\n",
    "ax[0,1].set_title('Conversion Rate vs. Pages Visited by Country')\n",
    "ax[0,1].set_xlabel('Pages Visited')\n",
    "ax[0,1].set_ylabel('Conversion Rate')\n",
    "ax[0,1].legend(title='Country')\n",
    "ax[0,1].grid(True)\n",
    "\n",
    "sns.lineplot(data=df, x='total_pages_visited', y='converted', hue='source', marker='o', ax=ax[1,1])\n",
    "ax[1,1].set_title('Conversion Rate vs. Pages Visited by Source')\n",
    "ax[1,1].set_xlabel('Pages Visited')\n",
    "ax[1,1].set_ylabel('Conversion Rate')\n",
    "ax[1,1].legend(title='Source')\n",
    "ax[1,1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Age vs. Conversion Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.groupby('age')['converted'].mean().reset_index()\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.lineplot(data=data, x='age', y='converted', marker='o', linestyle='-', color='#F7B32B')\n",
    "plt.title(\"Conversion Rate vs. Age\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Conversion Rate\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Categorical vs. Categorical Features\n",
    "- Use crosstabs or stacked bar charts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii. Target Variable Analysis\n",
    "\n",
    "- Analyze the target variable in the context of:\n",
    "    - Distribution: For numerical targets, plot histograms or boxplots.\n",
    "    - Class Balance: For classification tasks, check class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the 'converted'\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.countplot(x='converted', data=df)\n",
    "plt.title(\"Distribution of Conversion Status\")\n",
    "plt.xlabel(\"Converted (0 = Not Converted, 1 = Converted)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iv. Missing Data Analysis\n",
    "\n",
    "- Patterns of Missingness:\n",
    "    - Check if missing values are random or follow a pattern.\n",
    "- Imputation Strategies:\n",
    "    - Fill missing values with mean/median/mode, forward fill, or interpolation.\n",
    "    - For categorical features, use the most frequent category.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v. Time-Based Analysis\n",
    "\n",
    "- Trend Analysis:\n",
    "    - Plot trends over time for features like sales, clicks, etc.\n",
    "- Seasonality: Look for patterns across months, days, or hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i. Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fixed-Width Bins: You know meaningful ranges (e.g., decades or demographics).\n",
    "- Equal-Width Bins: Data ranges widely and you need uniform bins.\n",
    "- Quantile-Based Bins: Data is skewed, and you want evenly sized groups.\n",
    "- Statistical Measures: Binning by quartiles or percentiles for comparative analysis.\n",
    "- Clustering-Based Bins: Grouping based on natural clusters in the data.\n",
    "- Custom Conditions: Full control, such as age-based policies or rules.\n",
    "- Demographic Ranges: Predefined groups for demographic analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Bin Age into Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Clustering-Based Bins (K-Means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape age column for K-Means\n",
    "ages = df['age'].values.reshape(-1, 1)\n",
    "\n",
    "# Fit K-Means with 4 clusters\n",
    "kmeans = KMeans(n_clusters=4, random_state=42).fit(ages)\n",
    "\n",
    "# Assign cluster labels\n",
    "df['age_group_cluster_based'] = kmeans.labels_\n",
    "\n",
    "df.groupby('age_group_cluster_based')[['age', 'converted']].agg({'age':['min','max','count'], 'converted':['mean']}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Custom Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (df[\"age\"] <= 24),\n",
    "    (df[\"age\"] >= 25) & (df[\"age\"] <= 32),\n",
    "    (df[\"age\"] >= 33) & (df[\"age\"] <= 41),\n",
    "    (df[\"age\"] >= 42),\n",
    "]\n",
    "\n",
    "choices = ['0-24', '25-32', '33-41', '42+']\n",
    "\n",
    "df['custom_age_group'] = np.select(conditions, choices, default='Unknown')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Equal-width bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create equal-width bins\n",
    "bins = pd.interval_range(start=df['age'].min(), end=df['age'].max(), freq=20)  # Bin width = 20 years\n",
    "df['age_group_equal_width'] = pd.cut(df['age'], bins=bins)\n",
    "\n",
    "df.groupby('age_group_equal_width')[['age', 'converted']].agg({'age':['min','max','count'], 'converted':['mean']}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Quantile-based bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create quantile-based bins\n",
    "df['age_group_quantile_based'] = pd.qcut(df['age'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "\n",
    "df.groupby('age_group_quantile_based')[['age', 'converted']].agg({'age':['min','max','count'], 'converted':['mean']}).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Analyze Across Ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Age Groups vs. Conversion Rates\n",
    "Check the Relationship Between Age and Conversion Rate\n",
    "\n",
    "What to Look For:\n",
    "- Do conversion rates increase, decrease, or remain stable across age groups?\n",
    "- If conversion rates vary significantly, age likely plays a role in engagement and normalization may help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion rate by age group\n",
    "conversion_by_age = df.groupby('custom_age_group')['converted'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.barplot(data=conversion_by_age, x='custom_age_group', y='converted', palette='Blues_d')\n",
    "plt.title('Conversion Rate by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Conversion Rate')\n",
    "# plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = (\n",
    "#     df.groupby(\"custom_age_group\")[\"converted\"]\n",
    "#     .agg([\"mean\", \"count\"])\n",
    "#     .reset_index()\n",
    "#     .assign(mean=lambda x: x[\"mean\"] * 100)\n",
    "# )\n",
    "# fig, ax1 = plt.subplots(figsize=(15, 5))\n",
    "# sns.barplot(data=data, x=\"custom_age_group\", y=\"count\", ax=ax1, alpha=0.8)\n",
    "# ax1.set_ylabel(\"Count\", fontsize=12)\n",
    "# ax1.set_title(\"Conversion Counts and Rates by Age Group\", fontsize=12, pad=10)\n",
    "\n",
    "# ax2 = ax1.twinx()\n",
    "# sns.lineplot(\n",
    "#     data=data,\n",
    "#     x=\"custom_age_group\",\n",
    "#     y=\"mean\",\n",
    "#     marker=\"o\",\n",
    "#     linestyle=\"-\",\n",
    "#     linewidth=4,\n",
    "#     ax=ax2,\n",
    "#     color=\"#F7ACCF\",\n",
    "# )\n",
    "# ax2.set_ylabel(\"Conversion Rate\", fontsize=12)\n",
    "# ax2.yaxis.set_major_formatter(PercentFormatter())\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Age Groups vs. Pages Visited\n",
    "\n",
    "What to Look For:\n",
    "- Do younger or older users visit significantly more pages on average?\n",
    "- Is there high variability in total_pages_visited within certain age groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "sns.boxplot(data=df, x='custom_age_group', y='total_pages_visited')\n",
    "plt.title('Total Pages Visited Across Age Groups')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Total Pages Visited')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Age Groups vs. Pages Visited vs. Conversion Rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by age group and total pages visited, calculating the conversion rate\n",
    "data = df.groupby(['custom_age_group', 'total_pages_visited'])['converted'].mean().reset_index()\n",
    "\n",
    "# Create a FacetGrid to visualize conversion patterns across age groups and pages visited\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.lineplot(\n",
    "    data=data, \n",
    "    x='total_pages_visited', \n",
    "    y='converted', \n",
    "    hue='custom_age_group', \n",
    "    marker='o'\n",
    ")\n",
    "plt.title(\"Conversion Patterns for Age Groups by Total Pages Visited\")\n",
    "plt.xlabel(\"Total Pages Visited\")\n",
    "plt.ylabel(\"Conversion Rate\")\n",
    "plt.legend(title=\"Age Group\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on EDA, decide whether normalization is necessary:\n",
    "\n",
    "- Normalize If:\n",
    "\n",
    "    - total_pages_visited varies significantly across age groups.\n",
    "    - Conversion patterns differ for younger vs. older users with similar page visits.\n",
    "    - total_pages_visited and age interact in a way that directly influences conversion.\n",
    "- Do Not Normalize If:\n",
    "\n",
    "    - total_pages_visited has a strong independent relationship with converted regardless of age.\n",
    "    - age and total_pages_visited are weakly correlated or show no significant interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "\n",
    "- Conversion patterns differ for younger vs. older users with similar page visits:\n",
    "    - Younger age groups (0–24, 25–32) achieve higher conversion rates earlier (around 10–15 pages visited).\n",
    "    - Older age groups (33–41, 42+) require slightly more page visits (closer to 15–20) to reach similar conversion rates.\n",
    "- Interaction between age and total_pages_visited:\n",
    "    - There is a clear interaction between age and page visits, as the conversion rate's behavior varies by age group.\n",
    "    - This suggests that total pages visited alone may not be sufficient without considering the age factor.\n",
    "\n",
    "You should normalize or adjust for total_pages_visited across different age groups because the interaction between age and page visits impacts conversion behavior. This normalization will ensure fair comparisons and improve model accuracy when analyzing conversion patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. Interaction Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating interaction features involves combining two or more features to capture relationships that may improve your model's predictive performance. These interactions can help capture non-linear relationships or dependencies between variables that single features alone cannot explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of Interaction Features\n",
    "1. Numerical-Numerical Interactions\n",
    "    - Combine numerical features by performing arithmetic operations like:\n",
    "\n",
    "        - Multiplication\n",
    "        - Division\n",
    "        - Addition or subtraction\n",
    "2. Numerical-Categorical Interactions\n",
    "    - Combine numerical features with categorical features, such as grouping numerical features by categories.\n",
    "\n",
    "3. Categorical-Categorical Interactions\n",
    "    - Create interaction features by combining multiple categorical variables (e.g., cross-features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Methods to Create Interaction Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Numerical-Numerical Example\n",
    "Use arithmetic operations between numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_user_pages_interaction'] = df['new_user'] * df['total_pages_visited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How `new_user_pages_interaction` Impacts the Model**\n",
    "- Without the Interaction Feature:\n",
    "    - The model might treat new_user and total_pages_visited independently. For example:\n",
    "        - It might learn that being a new user has a weak positive effect on conversion.\n",
    "        - It might also learn that visiting more pages has a strong positive effect on conversion.\n",
    "- With the Interaction Feature:\n",
    "    - The model can now understand the conditional relationship:\n",
    "        - New users who visit many pages are more likely to convert.\n",
    "        - Existing users who visit many pages might have a different conversion pattern, which is not captured by this interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When to Use This Interaction**\n",
    "- Use `new_user * total_pages_visited` if:\n",
    "    - You believe new users' behavior (page visits) affects conversion differently than existing users.\n",
    "        - For example, new users might be more curious or engaged if they visit more pages, leading to higher conversion rates.\n",
    "    - You observe this pattern during Exploratory Data Analysis (EDA):\n",
    "        - Plot conversion rates against total_pages_visited for new users and existing users separately. If the patterns differ, this interaction is likely meaningful.\n",
    "\n",
    "\n",
    "The `age_pages_interaction` introduces a non-linear relationship between the features:\n",
    "\n",
    "- For example:\n",
    "    - A 25-year-old who visits 10 pages (age * total_pages_visited = 250) may behave differently than a 40-year-old who visits 10 pages (age * total_pages_visited = 400).\n",
    "    - The interaction may reveal patterns like \"older users who visit more pages are more likely to convert.\"\n",
    "- Hypothesis:\n",
    "    - Some age groups may require fewer or more pages to convert compared to others.\n",
    "    - Users who are older and visit many pages might show different behavior compared to younger users with the same level of engagement.\n",
    "\n",
    "**Scaling Before Multiplication**\n",
    "- If age and total_pages_visited have very different scales (e.g., age ranges from 17-100, but total_pages_visited ranges from 1-29), scale the features before creating the interaction to avoid large values dominating.\n",
    "\n",
    "**Alternative Interactions**\n",
    "- Categorical Interaction: Group total_pages_visited into bins (e.g., Low, Medium, High) and create a combined feature with new_user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins = [0, 5, 10, 20]\n",
    "# labels = ['Low', 'Medium', 'High']\n",
    "# data['pages_group'] = pd.cut(data['total_pages_visited'], bins=bins, labels=labels)\n",
    "# data['new_user_pages_group'] = data['new_user'].astype(str) + '_' + data['pages_group'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_pages_interaction'] = df['age'] * df['total_pages_visited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why Multiply Instead of Adding or Dividing?**\n",
    "- Multiplication (age * total_pages_visited):\n",
    "    - Amplifies the combined effect of age and total_pages_visited.\n",
    "    - Captures non-linear patterns where the two features interact strongly.\n",
    "- Addition (age + total_pages_visited):\n",
    "    - Simpler but less powerful for non-linear relationships.\n",
    "- Division (total_pages_visited / age):\n",
    "    - Useful if you think normalized engagement by age matters (e.g., younger users with high pages relative to their age).\n",
    "        - Younger users may be more engaged on average than older users, and their behavior (e.g., pages visited) needs to be compared relative to their typical age group behavior.\n",
    "        - Example: A 20-year-old visiting 5 pages might show low engagement, but a 60-year-old visiting 5 pages could indicate high engagement.\n",
    "    - When Age Moderates Engagement\n",
    "        - If the relationship between engagement (e.g., total pages visited) and conversion depends on age, normalized metrics can help capture this interaction.\n",
    "        - For example, younger users may need to visit fewer pages to convert, while older users may need more.\n",
    "    - Adjusting for Different User Expectations\n",
    "        - Certain age groups may inherently exhibit different browsing patterns:\n",
    "            - Younger users might visit fewer pages due to shorter attention spans.\n",
    "            - Older users might browse more pages to make informed decisions.\n",
    "        - Normalizing helps adjust for these natural tendencies to better understand conversion likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avoid using the interaction feature if:\n",
    "\n",
    "- The relationship between age and total_pages_visited is weak or independent.\n",
    "- Your model is tree-based (e.g., Random Forest, XGBoost), as these algorithms capture interactions naturally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a normalized feature by dividing total_pages_visited by age. It assumes that engagement should be proportional to age.\n",
    "df['pages_per_age'] = df['total_pages_visited'] / (df['age'] + 1)  # Add 1 to avoid division by zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Numerical-Categorical Example\n",
    "Multiply or group numerical features by categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It involves calculating aggregate statistics (e.g., mean, median, sum) for a numerical feature within groups defined by a categorical feature.\n",
    "\n",
    "- Example:\n",
    "    - Numerical Feature: total_pages_visited\n",
    "    - Categorical Feature: country (e.g., US, UK, Germany)\n",
    "- Result:\n",
    "    - Calculate the mean pages visited for users in each country.\n",
    "\n",
    "\n",
    "Why Group Numerical Features by Categorical Variables?\n",
    "- (a) Reveal Group-Specific Patterns: Grouping helps identify how numerical behavior varies across categories.\n",
    "    - Example:\n",
    "        - Do users from different countries (country) visit more or fewer pages (total_pages_visited) on average?\n",
    "    - Insights:\n",
    "        - Users from \"US\" might visit more pages than users from \"Germany.\"\n",
    "        - This could indicate differences in engagement across countries.\n",
    "- (b) Create Features for Modeling: Aggregated statistics (e.g., mean, max, sum) can be used as new features in your machine learning model. They help capture group-level effects.\n",
    "- (c) Highlight Outliers: Grouping can help detect outliers within specific categories.\n",
    "    - Example:\n",
    "        - If the mean number of pages visited in the \"UK\" is 3, and a user from the \"UK\" visits 20 pages, this might be an anomaly worth investigating.\n",
    "\n",
    "When Should You Group Numerical Features by Categorical Variables?\n",
    "- Use Cases:\n",
    "    - Category-Dependent Behavior:\n",
    "    - When numerical variables are influenced by categorical groupings.\n",
    "        - Example: Engagement (pages visited) varies across countries or marketing sources.\n",
    "    - Outlier Detection:\n",
    "        - Find users whose behavior deviates significantly from their group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pages_by_country = df.groupby('country')['total_pages_visited'].transform('mean')\n",
    "df['pages_vs_country_mean'] = df['total_pages_visited'] / mean_pages_by_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Categorical-Categorical Example\n",
    "Combine two or more categorical features using concatenation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Combine Categorical Features?\n",
    "- (a) Capture Interactions Between Categories\n",
    "    - Some categorical variables may have interacting effects on the target variable. Analyzing them in isolation may miss this relationship.\n",
    "\n",
    "        - Example:\n",
    "            - country and source independently affect conversion, but the combination of country and source might reveal stronger patterns.\n",
    "            - Users from the \"US\" converting through \"SEO\" might behave differently than users from \"UK\" through \"Direct.\"\n",
    "- (b) Create More Granular Groups\n",
    "    - Concatenation creates finer-grained categories, which may better represent the data.\n",
    "    - Example:\n",
    "        - If country has 3 categories and source has 3 categories, combining them creates 9 unique groups.\n",
    "        - This allows the model to differentiate between granular segments like US_SEO vs. US_Ads.\n",
    "- (c) Improve Predictive Power\n",
    "    - Models like linear models (e.g., Logistic Regression) and tree-based models (e.g., Random Forest, XGBoost) often perform better when provided with interaction terms. Combining categorical features explicitly informs the model about the interactions.\n",
    "- (d) Uncover Hidden Insights\n",
    "    - EDA using combined categorical features can uncover hidden relationships that are not apparent when analyzing each feature independently.\n",
    "    - Example:\n",
    "        - Users from \"Germany\" might perform poorly overall, but users from \"Germany\" who come through \"SEO\" might convert well. This insight is only visible when combining country and source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When Should You Combine Categorical Features?\n",
    "\n",
    "- Suspected Interactions:\n",
    "    - When you believe that two or more categories interact and jointly affect the target.\n",
    "        - Example: marketing_channel and device_type (e.g., \"SEO + Mobile\" vs. \"SEO + Desktop\").\n",
    "- High Cardinality Features:\n",
    "    - If your original categorical features have low cardinality (few unique values), combining them won't lead to an explosion in the number of categories.\n",
    "    - Example:\n",
    "        - country (3 categories) × source (3 categories) = 9 combined categories.\n",
    "- Improving Model Performance:\n",
    "    - For linear models or when your current features aren't providing enough predictive power.\n",
    "- Segmentation Analysis:\n",
    "    - Helps you analyze specific groups in detail.\n",
    "    - Example: \"US_SEO\" may have a conversion rate of 10%, while \"Germany_Direct\" is 2%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When Not to Combine Categorical Features\n",
    "- High Cardinality Explosion:\n",
    "    - If the original categorical features have many unique values, combining them can lead to an unmanageable number of unique categories.\n",
    "    - Example:\n",
    "        - city (500 categories) × source (10 categories) = 5000 combined categories.\n",
    "- Sparse Data:\n",
    "    - If your dataset is small, combining categorical features can result in sparse data, where some combinations appear infrequently or not at all.\n",
    "- Tree-Based Models:\n",
    "    - Tree-based models (e.g., Random Forest, XGBoost) can automatically capture interactions between features. Explicitly combining categories might be redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Combine `country` and `source` into a single feature\n",
    "# data['country_source_interaction'] = data['country'] + '_' + data['source']\n",
    "\n",
    "# If your model requires numerical input, encode the new feature (e.g., one-hot or label encoding):\n",
    "\n",
    "# data = pd.get_dummies(data, columns=['country_source_interaction'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Best Practices\n",
    "- Domain Knowledge: Focus on interactions that make logical sense in your context (e.g., new_user * total_pages_visited might reflect user engagement).\n",
    "- Avoid Overfitting: Be cautious when creating too many interaction features, especially for small datasets.\n",
    "- Model-Specific Considerations:\n",
    "    - Tree-based models (e.g., Random Forest, XGBoost) can capture interactions naturally, so explicit interaction features might be redundant.\n",
    "    - Linear models (e.g., Logistic Regression) often benefit significantly from interaction features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii. Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['country', 'source'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When Should You Encode Age Bins?\n",
    "- Yes, encode if:\n",
    "    - You plan to use age_group as a feature in your model.\n",
    "    - Binning introduces meaningful categorical distinctions (e.g., age ranges like 0-20, 21-40).\n",
    "    - Use **one-hot encoding** for linear models or when the bins have no inherent order.\n",
    "    - Use **label encoding** or **ordinal mapping** for tree-based models or when the bins have a natural order.\n",
    "- No, do not encode if:\n",
    "    - You decide to work with the raw numerical age directly without binning.\n",
    "    - The model (e.g., tree-based methods like Random Forest or XGBoost) can handle the numerical representation without encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode the age group\n",
    "label_encoder = LabelEncoder()\n",
    "df['age_group_encoded'] = label_encoder.fit_transform(df['custom_age_group'])\n",
    "print(df[['custom_age_group', 'age_group_encoded']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Normalize/Scale Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling numerical features is an essential step in preparing data for machine learning models, especially when features have different scales or ranges. Whether or not you need to scale depends on the type of model you're using and the nature of the data.\n",
    "\n",
    "1. Why Scale Numerical Features?\n",
    "    - Ensure Equal Contribution: Features with larger ranges can dominate those with smaller ranges in distance-based models (e.g., k-NN) or optimization algorithms (e.g., gradient descent).\n",
    "    - Improve Convergence: Scaling speeds up convergence in gradient-based optimization algorithms (e.g., in Logistic Regression, Neural Networks).\n",
    "    - Prevent Numerical Instability: Extremely large feature values can cause numerical instability in some algorithms.\n",
    "\n",
    "2. When to Scale Numerical Features\n",
    "    - (a) Always Scale When Using Distance-Based Algorithms\n",
    "        - For models where distances or similarity measures are important, scaling ensures that all features contribute equally.\n",
    "\n",
    "        - Examples:\n",
    "            - k-Nearest Neighbors (k-NN): Uses Euclidean or Manhattan distance; unscaled features with large ranges dominate the distance calculation.\n",
    "            - Support Vector Machines (SVM): Uses a kernel function (e.g., radial basis function) that depends on distances.\n",
    "            - Principal Component Analysis (PCA): Maximizes variance; unscaled features with large variance dominate the principal components.\n",
    "            - Clustering (e.g., K-Means): Relies on distances to assign clusters; unscaled features distort the clusters.\n",
    "\n",
    "    - (b) Scale for Gradient-Based Models\n",
    "        - Models that rely on gradient descent optimization (e.g., Logistic Regression, Neural Networks) benefit from scaling, as it ensures:\n",
    "            - Faster convergence.\n",
    "            - Balanced updates for all weights during training.\n",
    "        - Examples:\n",
    "            - Logistic Regression\n",
    "            - Neural Networks\n",
    "            - Linear Regression (if regularized, e.g., Ridge, Lasso)\n",
    "    - (c) Scale for Regularized Models\n",
    "        - Regularization techniques penalize the magnitude of coefficients (e.g., L1/L2 regularization in Ridge, Lasso, or ElasticNet). Without scaling, the regularization terms are biased toward features with larger ranges.\n",
    "        - Examples:\n",
    "            - Ridge Regression\n",
    "            - Lasso Regression\n",
    "            - ElasticNet\n",
    "    - (d) When Feature Values Have Drastically Different Ranges\n",
    "        - If numerical features have drastically different scales, scaling is required to prevent models from being biased toward features with larger ranges.\n",
    "\n",
    "3. When Not to Scale\n",
    "    - (a) Tree-Based Models\n",
    "        - Decision trees and ensemble models like Random Forest, XGBoost, LightGBM, and CatBoost do not require scaling, as they are not sensitive to the magnitude of feature values.\n",
    "        - Why?:\n",
    "            - These models split features based on thresholds (e.g., age > 30), not distances or gradients.\n",
    "    - (b) Features with Meaningful Units\n",
    "        - Some features have ranges that are meaningful or interpretable in their original units. Scaling might make these values harder to interpret.\n",
    "        - Examples:\n",
    "            - house_price (in dollars): Scaling might obscure meaningful dollar values.\n",
    "            - number_of_items_sold: The raw counts are often interpretable as-is.\n",
    "    - (c) When All Features Are on the Same Scale\n",
    "        - If all numerical features already have similar ranges, scaling is unnecessary.\n",
    "        - Examples:\n",
    "            - temperature (in °C) and precipitation (in mm), both ranging from 0 to 100.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i. Scaling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Standardization (Z-Score Scaling)\n",
    "Standardization rescales features to have a mean of 0 and standard deviation of 1. Use this when features are approximately normally distributed.\n",
    "\n",
    "Best For:\n",
    "- Gradient-based models\n",
    "- Regularized models\n",
    "- PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# data[['age_scaled', 'income_scaled']] = scaler.fit_transform(data[['age', 'income']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Min-Max Scaling\n",
    "Scales features to a specific range (default: 0 to 1). Use this when all features need to be scaled proportionally.\n",
    "Best For:\n",
    "- Distance-based models (e.g., k-NN, k-Means)\n",
    "- When features have a non-Gaussian distribution\n",
    "- Neural networks (ensures all features have similar weight initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# data[['age_scaled', 'income_scaled']] = scaler.fit_transform(data[['age', 'income']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Robust Scaling\n",
    "Scales features using the median and interquartile range, making it robust to outliers.\n",
    "Best For:\n",
    "- Datasets with outliers\n",
    "- Gradient-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# scaler = RobustScaler()\n",
    "# data[['age_scaled', 'income_scaled']] = scaler.fit_transform(data[['age', 'income']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. Visualizing the Need for Scaling\n",
    "\n",
    "What to Look For:\n",
    "- Scaling ensures features have similar ranges and contribute equally to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(data=data[['age', 'income']])\n",
    "# plt.title('Feature Ranges Before Scaling')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_data = StandardScaler().fit_transform(data[['age', 'income']])\n",
    "# sns.boxplot(data=pd.DataFrame(scaled_data, columns=['age_scaled', 'income_scaled']))\n",
    "# plt.title('Feature Ranges After Scaling')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Split Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\n",
    "    [\n",
    "        \"age_group_cluster_based\",\n",
    "        \"age_group_equal_width\",\n",
    "        \"age_group_quantile_based\",\n",
    "        \"custom_age_group\",\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('converted', axis=1)  # Features\n",
    "y = df['converted']              # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i. Understand Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Correlation Analysis (For Numerical Features)\n",
    "\n",
    "- Check the correlation between numerical features and the target variable (e.g., converted).\n",
    "- Remove features with very low or no correlation with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical columns only\n",
    "numerical_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = numerical_df.corr()\n",
    "print(correlation['converted'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Feature Importance from Models\n",
    "- Use tree-based models like Random Forest, Gradient Boosting (e.g., XGBoost, LightGBM) to compute feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "feature_importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "print(feature_importances.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. Use Statistical Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Chi-Square Test (For Categorical Features)\n",
    "- Measure the dependency of categorical features on the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import chi2\n",
    "# chi_scores, p_values = chi2(X_train, y_train)\n",
    "# print(p_values)  # Features with low p-values are significant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. ANOVA F-Test\n",
    "- Use F-test for numerical features to check how well they distinguish the target variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii. Feature Selection Based on Domain Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Cross-Validation for Feature Subsets\n",
    "- Train models with different subsets of features and compare performance using cross-validation (e.g., AUC, F1 score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iv. Automated Feature Selection Tools\n",
    "- Use libraries like Boruta or SHAP for automated and interpretable feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy\n",
    "rf = RandomForestClassifier()\n",
    "boruta_selector = BorutaPy(rf, n_estimators='auto', random_state=42)\n",
    "boruta_selector.fit(X_train.values, y_train.values)\n",
    "selected_features = X_train.columns[boruta_selector.support_]\n",
    "print(selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v. Dimensionality Reduction\n",
    "- If you have a large number of features:\n",
    "    - Use PCA (Principal Component Analysis) to reduce dimensionality while retaining variance.\n",
    "    - Be cautious when using PCA for interpretability-focused models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components=10)  # Reduce to 10 components\n",
    "# X_pca = pca.fit_transform(X_train)\n",
    "# print(pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Train Predictive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[selected_features]  # Features\n",
    "y = df['converted']              # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i. Logistic Regression\n",
    "Start with a simple model as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"AUC: {roc_auc_score(y_test, logreg.predict_proba(X_test)[:, 1]):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. Decision Tree / Random Forest\n",
    "Use tree-based models to capture non-linear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train random forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii. Gradient Boosting (e.g., XGBoost, LightGBM)\n",
    "Boosting models often outperform simpler models in binary classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "xgb = XGBClassifier(eval_metric='auc', random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "y_pred = xgb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Model Evaluation\n",
    "\n",
    "Evaluate your models on metrics like:\n",
    "- Accuracy: The proportion of correct predictions.\n",
    "- Precision: The ability of the model to avoid false positives (relevant for imbalanced classes).\n",
    "- Recall (Sensitivity): The ability to identify all true positives.\n",
    "- F1-Score: A balance between precision and recall.\n",
    "- AUC-ROC: Measures the ability to discriminate between positive and negative classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i. ROC and Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Logistic Regression\n",
    "y_pred_proba_lr = logreg.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_lr)\n",
    "plt.plot(fpr, tpr, label=\"Logistic Regression (AUC=%.2f)\" % roc_auc_score(y_test, y_pred_proba_lr))\n",
    "\n",
    "# Random Forest\n",
    "y_pred_proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_proba_rf)\n",
    "plt.plot(fpr_rf, tpr_rf, label=\"Random Forest (AUC=%.2f)\" % roc_auc_score(y_test, y_pred_proba_rf))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression slightly outperforms Random Forest in precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Logistic Regression\n",
    "cm_lr = confusion_matrix(y_test, logreg.predict(X_test))\n",
    "ConfusionMatrixDisplay(cm_lr).plot(cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(\"Logistic Regression Confusion Matrix\")\n",
    "\n",
    "# Random Forest\n",
    "cm_rf = confusion_matrix(y_test, rf.predict(X_test))\n",
    "ConfusionMatrixDisplay(cm_rf).plot(cmap=\"Greens\", values_format=\"d\")\n",
    "plt.title(\"Random Forest Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If recall (catching all conversions) is critical, focus on improving models to reduce False Negatives (e.g., use SMOTE for balancing the classes).\n",
    "- If precision (avoiding false positives) is more important, Logistic Regression already does well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Logistic Regression\n",
    "scores_lr = cross_val_score(logreg, X_train, y_train, cv=5, scoring=\"f1\")\n",
    "print(\"Logistic Regression F1 Cross-Validation Scores:\", scores_lr)\n",
    "print(\"Mean F1:\", scores_lr.mean())\n",
    "\n",
    "# Random Forest\n",
    "scores_rf = cross_val_score(rf, X_train, y_train, cv=5, scoring=\"f1\")\n",
    "print(\"Random Forest F1 Cross-Validation Scores:\", scores_rf)\n",
    "print(\"Mean F1:\", scores_rf.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Provide Recommendations\n",
    "Based on the model results and feature importance, provide actionable insights:\n",
    "\n",
    "1. Feature Importance:\n",
    "\n",
    "    - Use SHAP values or model coefficients to understand which features drive conversion.\n",
    "    - Example: If total_pages_visited has high importance, encourage users to view more pages by improving navigation or content.\n",
    "2. Segment Analysis:\n",
    "\n",
    "    - Identify underperforming segments (e.g., low conversion rates for specific country or source) and target them with customized strategies.\n",
    "3. Test Ideas to Improve Revenue:\n",
    "\n",
    "    - For new users (new_user=1), create onboarding flows to improve engagement.\n",
    "    - Invest in high-performing sources (e.g., SEO) while revisiting strategies for weaker ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Insight**: Users with higher page visits tend to convert more often, as observed from EDA (steep conversion increase between 10–20 pages visited).\n",
    "\n",
    "- **Recommendation**:\n",
    "    - Encourage users to visit more pages by optimizing internal linking and providing engaging content (e.g., recommended pages).\n",
    "    - Add incentives (e.g., discounts or pop-ups) when users cross a threshold of visited pages to push conversions.\n",
    "\n",
    "- **Insight**: Conversion patterns vary significantly for younger and older users, especially for similar levels of engagement.\n",
    "    - Younger users may require fewer page visits to convert, while older users need more engagement.\n",
    "- **Recommendation**:\n",
    "    - Personalize the user experience by age group:\n",
    "    - Younger Users: Streamline the user journey (fewer pages, quicker call-to-action).\n",
    "    - Older Users: Provide more detailed content or targeted information to build trust.\n",
    "\n",
    "- **Insight**: Some age groups (e.g., younger users) may naturally visit more pages per unit of time, driving conversion rates up.\n",
    "- **Recommendation**:\n",
    "    - Use age-targeted marketing campaigns:\n",
    "    - For older users, reduce friction by displaying essential information upfront.\n",
    "    - For younger users, leverage engaging visuals or interactive elements to maintain interest.\n",
    "\n",
    "\n",
    "- **Insight**: Users who visit significantly more pages than their country’s average may be more likely to convert.\n",
    "- **Recommendation**:\n",
    "    - Optimize the experience for underperforming regions:\n",
    "    - Identify countries with lower average page visits and localize content (e.g., language, cultural preferences).\n",
    "    - Test regional variations of the website to improve engagement.\n",
    "\n",
    "\n",
    "***Recommendations Summary***\n",
    "- Enhance Page Engagement:\n",
    "    - Improve internal linking and recommended content to encourage more page visits.\n",
    "    - Use pop-ups or incentives to reward high engagement (e.g., after visiting 10 pages).\n",
    "- Age-Based Personalization:\n",
    "    - Simplify journeys for younger users with quick actions.\n",
    "    - Provide more detailed content for older users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Deployment\n",
    "If you're satisfied with the model's performance:\n",
    "\n",
    "- Save the model using joblib or pickle.\n",
    "- Deploy it in production to predict conversion probabilities for new users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
